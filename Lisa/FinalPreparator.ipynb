{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalPreparator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qRpsJvmQtz7",
        "outputId": "b9dbc044-9246-4851-a5e0-3be6f34eecff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmAX_upMQ21S",
        "outputId": "8f4a1bfb-6d8e-4942-ac42-ee9bf4ab2f14"
      },
      "source": [
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting DAWG>=0.8\n",
            "  Downloading DAWG-0.8.0.tar.gz (371 kB)\n",
            "\u001b[K     |████████████████████████████████| 371 kB 53.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp37-cp37m-linux_x86_64.whl size=849485 sha256=dbc158d980bd436dec93d1f8e25c357d72ac61428702ecd80ee174d1b0745af0\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/51/a4/2de41ff197786537075027c27b479a38da92f50abc86634445\n",
            "Successfully built DAWG\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2, DAWG\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFn8K43kQ7FN"
      },
      "source": [
        "import random\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models import LdaMulticore\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import warnings \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from PIL import Image\n",
        "from IPython.display import clear_output\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from typing import List\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "from typing import List\n",
        "import nltk\n",
        "import string\n",
        "import pymorphy2\n",
        "import codecs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f4wM1KrQ_7V"
      },
      "source": [
        "warnings.filterwarnings(action='ignore',category=UserWarning, module='gensim')  \n",
        "warnings.filterwarnings(action='ignore',category=FutureWarning, module='gensim')  \n",
        "warnings.filterwarnings(action='ignore',category=DeprecationWarning, module='gensim')\n",
        "warnings.filterwarnings(action='ignore',category=DeprecationWarning, module='smart_open') \n",
        "warnings.filterwarnings(action='ignore',category=DeprecationWarning, module='sklearn')\n",
        "warnings.filterwarnings(action='ignore',category=DeprecationWarning, module='scipy')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7S0kJJyRFn8"
      },
      "source": [
        "class Preparator():\n",
        "  def __init__(self):\n",
        "      self.morph = pymorphy2.MorphAnalyzer()\n",
        "      self.tokenizer = nltk.WordPunctTokenizer()\n",
        "      self.stopwords = set(line.strip() for line in codecs.open('/content/drive/MyDrive/aiijc_sber/all_stopwords.txt', \"r\", \"utf_8_sig\").readlines())\n",
        "      self.bigram_mod = gensim.models.Phrases.load(\"/content/drive/MyDrive/aiijc_sber/bigram_model.pkl\")\n",
        "\n",
        "  def prepare_corp(self, news_list: List[str]):\n",
        "      return [self.newstext2token(news_text) for news_text in news_list]\n",
        "\n",
        "  def make_bigrams(self, doc):\n",
        "      return self.bigram_mod[doc]\n",
        "\n",
        "  def newstext2token(self, news_text: str):\n",
        "      tokens = self.tokenizer.tokenize(news_text.lower())\n",
        "      tokens_with_no_punct = [self.morph.parse(w)[0].normal_form for w in tokens if all(c in 'йцукенгшщзхъёфывапролджэячсмитьбю' for c in w)]\n",
        "      tokens_base_forms = [w for w in tokens_with_no_punct if w not in self.stopwords]\n",
        "      tokens_last = [w for w in tokens_base_forms if len(w)>1]\n",
        "      tokens_bigrammed = self.make_bigrams(tokens_last)\n",
        "      return tokens_bigrammed\n",
        "\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Dg38hMRiJ8",
        "outputId": "e4407604-0a74-489d-933a-b6211bc9642c"
      },
      "source": [
        "print(Preparator().newstext2token('Глобус - модель земного шара'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['глобус', 'модель', 'земной_шар']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FxMaf7mXtzd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}