{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPD5xkHjefGd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTfGP2b6Adn3"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRYkmf3b98vd"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import string\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjpegAf1_GJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f301c50f-bbde-4630-9825-81e84d36a2f2"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        " \n",
        "if device == torch.device('cpu'):\n",
        "    print('Using cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Tesla K80 GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnXtMN6RE_i4"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNcjmF9KrOZB"
      },
      "source": [
        "save_path = '/content/drive/MyDrive'\n",
        "df_test = pd.read_csv(save_path + '/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIuHgDn2luV6"
      },
      "source": [
        "# Facts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E0IX9PFlseJ"
      },
      "source": [
        "df = pd.read_csv(save_path + '/facts2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EsrPQdN-4IQ"
      },
      "source": [
        "df_new = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH98Wq2TziDX"
      },
      "source": [
        "# full_marked_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-hk8c4lzZs3"
      },
      "source": [
        "df = pd.read_csv(save_path + '/full_marked_dataset.csv')\n",
        "df = df.drop('Unnamed: 0', 1)\n",
        "df = df.rename(columns={'text': 'texts', 'ans': 'labels'})\n",
        "df.labels = df.labels.replace('животные', 0).replace('музыка', 1).replace('спорт', 2).replace('литература', 3).replace('неизвестно', 4)\n",
        "df = df.drop([i for i in range(len(df.labels)) if df.labels[i] == 4], 0)\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovazZVao-7eP"
      },
      "source": [
        "# Facts & full_marked_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbCDrYnZ-6gl"
      },
      "source": [
        "for i in range(len(df_new)):\n",
        "  df.loc[-i-1] = df_new.loc[i]\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X-y_j7IE5Pg"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "883a2936"
      },
      "source": [
        "categories = (\"животные\", \"музыка\", \"спорт\", \"литература\")\n",
        "catToCatTest = {'животные':3, 'музыка':1, 'спорт':0, 'литература':2} # Т.к. в размеченном тестовом цифры обозначают другие классы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86KGIlRwwCd"
      },
      "source": [
        "sentMaxLen = 50 # Дальше датасет разбивается на блоки по столько слов\n",
        "max_len_tokenized = 200 # Максимальное количество токенов, которые подаются берту для обучения\n",
        "max_test = 200 # Максимальное количество слов, которые подаются берту для теста"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxbmPOVmmeVq"
      },
      "source": [
        "alphabet = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя ')\n",
        "\n",
        "def generateTexts(texts, windowLen, only_long=True):\n",
        "  out = []\n",
        "  for text in texts:\n",
        "    text = text.lower().replace('\\n', ' ')\n",
        "    text = ''.join(c for c in text if c in alphabet)\n",
        "    text = text.split()\n",
        "    if only_long: # Все примеры длины windowLen\n",
        "      out.extend([' '.join(text[x:x+windowLen]) for x in range(0, len(text)-windowLen, windowLen)])\n",
        "    else:\n",
        "      out.extend([' '.join(text[x:x+windowLen]) for x in range(0, len(text), windowLen)])\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuc_PL2_oPYT"
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        " \n",
        "for i in range(len(df.texts)):\n",
        "  cat_texts = generateTexts([df.texts[i]], sentMaxLen, only_long=False)\n",
        "  label = df.labels[i]\n",
        "  for j in cat_texts:\n",
        "    sentences.append(j)\n",
        "    labels.append(label)\n",
        " \n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "X_train = np.array(sentences)\n",
        "Y_train = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6C6raB6KhYT"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\", do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in X_train]\n",
        "tokenized_texts = pad_sequences(\n",
        "  tokenized_texts,\n",
        "  maxlen=max_len_tokenized,\n",
        "  dtype=object,\n",
        "  truncating=\"post\",\n",
        "  padding=\"post\",\n",
        "  value='[PAD]'\n",
        ")\n",
        "attention_masks = [[1 if i != '[PAD]' else 0 for i in seq] for seq in tokenized_texts]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO4N-7wzNLQB"
      },
      "source": [
        "train_inputs = torch.tensor(input_ids)\n",
        "train_labels = torch.tensor(Y_train)\n",
        "train_masks = torch.tensor(attention_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQlkgEm2NSra"
      },
      "source": [
        "cnt_steps_batch = 2 # Увеличение батча во столько раз (после стольких батчей обновляются веса)\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "  train_data,\n",
        "  sampler=RandomSampler(train_data),\n",
        "  batch_size=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZdB2Hw0NpUJ"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=4, output_hidden_states=True, output_attentions=True)\n",
        "#model.load_state_dict(torch.load(save_path + '/model.pth'))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d63qzJeuNzfY"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "  {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.01},\n",
        "  {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbi9MLv4fvwU"
      },
      "source": [
        "def prediction(sentence, max_key_words=1):\n",
        "  sentence = sentence.lower().replace('\\n', ' ').replace('ё', 'е').replace('й', 'и')\n",
        "  sentence = ''.join(c for c in sentence if c in alphabet)\n",
        "  sentence = ' '.join(sentence.split()[:max_test])\n",
        "  sentence = '[CLS] ' + sentence + ' [SEP]'\n",
        "  words = sentence.split()\n",
        "  tokenized = tokenizer.tokenize(sentence)\n",
        "\n",
        "  # Получение для каждого токена индекса слова, из которого сделан этот токен\n",
        "  now_word = 0\n",
        "  now_ind = 0\n",
        "  token_to_word = []\n",
        "  for i in tokenized:\n",
        "    token_to_word.append(now_word)\n",
        "    for j in range(len(i)):\n",
        "      if i[j] != words[now_word][now_ind]:\n",
        "        continue\n",
        "      now_ind += 1\n",
        "      if now_ind == len(words[now_word]):\n",
        "        now_ind = 0\n",
        "        now_word += 1\n",
        "  \n",
        "  # Предсказание модели и получение attention\n",
        "  ids = [tokenizer.convert_tokens_to_ids(tokenized)]\n",
        "  ids = torch.tensor(ids)\n",
        "  ids = ids.to(device)\n",
        "  label = torch.tensor([0]).to(device)\n",
        "  with torch.no_grad():\n",
        "    logits = model(ids, token_type_ids=None, attention_mask=None, labels=label)\n",
        "  \n",
        "  ans = logits[1].detach().to('cpu').numpy()\n",
        "  ans_ind = np.argmax(ans, axis=1).item()\n",
        "  ans_cat = categories[ans_ind]\n",
        "\n",
        "  attention = logits[3][11][0][11][0].detach().to('cpu').numpy()\n",
        "\n",
        "  # Получение самых важных max_key_words слов\n",
        "  max_inds = np.flip(np.argsort(attention))\n",
        "  all_key_words = ['[SEP]', '[CLS]']\n",
        "  for i in max_inds:\n",
        "    # Просмотр новых слов до получения max_key_words самых важных слов или до просмотра всех слов\n",
        "    if words[token_to_word[i]] in all_key_words:\n",
        "      continue\n",
        "    all_key_words.append(words[token_to_word[i]])\n",
        "    if len(all_key_words)-2 == max_key_words:\n",
        "      break\n",
        "  return ans_cat, all_key_words[2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTfNZ44FN3tY"
      },
      "source": [
        "def model_train(epochs=1):\n",
        "  test_acc = []\n",
        "  test_f1 = []\n",
        "  for ep in range(epochs):\n",
        "    train_loss_set = []\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      \n",
        "      loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "      \n",
        "      train_loss_set.append(loss[0].item())  \n",
        "      \n",
        "      loss_back = loss[0] / cnt_steps_batch\n",
        "\n",
        "      loss_back.backward()\n",
        "      \n",
        "      if (step+1)%cnt_steps_batch == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "      \n",
        "      clear_output(True)\n",
        "      plt.plot(train_loss_set)\n",
        "      plt.title(f\"Training loss on epoch {ep+1}/{epochs}\")\n",
        "      plt.xlabel(\"Batch\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.show()\n",
        "      print('Эпоха: accuracy, f1')\n",
        "      for i in range(len(ep)):\n",
        "        print(str(i+1) + '/' + str(epochs) + ': ' + str(test_acc[i]) + ', ' + str(test_f1[i]))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_labels = df_test.ans\n",
        "    test_preds = []\n",
        "\n",
        "    for text in df_test.task:\n",
        "      ans_cat, _ = prediction(text)\n",
        "      test_preds.append(catToCatTest[ans_cat])\n",
        "\n",
        "    test_acc.append(accuracy_score(test_labels, test_preds))\n",
        "    test_f1.append(f1_score(test_labels, test_preds, average='macro'))\n",
        "\n",
        "    torch.save(model.state_dict(), save_path + f'/model_{ep}.pth')\n",
        "\n",
        "    clear_output(True)\n",
        "    print('Эпоха: accuracy, f1')\n",
        "    for i in range(len(ep+1)):\n",
        "      print(str(i+1) + '/' + str(epochs) + ': ' + str(test_acc[i]) + ', ' + str(test_f1[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9NzD3Bd4uoK"
      },
      "source": [
        "model_train(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a48zM7vaQ4I"
      },
      "source": [
        "torch.save(model.state_dict(), save_path + '/model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynyn_t93ECwu"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv0mjFgxNjRZ",
        "outputId": "79de0708-999f-4969-cdac-e0f716ca8759"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "test_labels = df_test.ans\n",
        "test_preds = []\n",
        "\n",
        "for text in df_test.task:\n",
        "  ans_cat, _ = prediction(text)\n",
        "  test_preds.append(catToCatTest[ans_cat])\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(test_labels, test_preds)}\")\n",
        "print(f\"F1: {f1_score(test_labels, test_preds, average='macro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8521400778210116\n",
            "F1: 0.8247984565417513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSKfnzp5X4on",
        "outputId": "13c9ce56-2317-4994-c876-1498e61bb66b"
      },
      "source": [
        "ans_cat, all_key_words = prediction('1.29. Вороны высиживают яйца три недели. Сколько дней высиживают яйца вороны?', 3)\n",
        "print(ans_cat)\n",
        "print(all_key_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "животные\n",
            "['вороны', 'яица', 'высиживают']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74hVZYzaCz-Z"
      },
      "source": [
        "ans_csv = []\n",
        "for i, text in enumerate(df_test.task):\n",
        "  ans_cat, all_key_words = prediction(text, 3)\n",
        "  ans_csv.append([i, ans_cat, '; '.join(all_key_words)])\n",
        "\n",
        "ans_df = pd.DataFrame(ans_csv, columns=['id', 'category', 'keywords'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "MBS4MWIeEZjR",
        "outputId": "5bc37885-be7f-4922-cd7a-d3aebb140429"
      },
      "source": [
        "ans_df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>спорт</td>\n",
              "      <td>у; хоккею; сеичас</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>животные</td>\n",
              "      <td>собак; коробки; корма</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>спорт</td>\n",
              "      <td>выбора; учащимся; навравления</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>литература</td>\n",
              "      <td>вопросы; вопрос; задачи</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>литература</td>\n",
              "      <td>тетради; множество; изобразите</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>спорт</td>\n",
              "      <td>при; он; дима</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>литература</td>\n",
              "      <td>книг; сотыхвычисли; сотых</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>спорт</td>\n",
              "      <td>причем; гребца; но</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>спорт</td>\n",
              "      <td>машина; наиди; ехала</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>спорт</td>\n",
              "      <td>раздевалки; спортзала; гребцов</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>литература</td>\n",
              "      <td>сочинения; сочинении; написать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>спорт</td>\n",
              "      <td>бассеина; раздевалки; пола</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>спорт</td>\n",
              "      <td>ловли; м; судака</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>спорт</td>\n",
              "      <td>в; запиши; расстояние</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>спорт</td>\n",
              "      <td>он; турист; пошел</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>спорт</td>\n",
              "      <td>велосипедиста; пешехода; определи</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>спорт</td>\n",
              "      <td>девушки; ведь; в</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>литература</td>\n",
              "      <td>книге; о; кулинарии</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>спорт</td>\n",
              "      <td>было; где; беговая</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>литература</td>\n",
              "      <td>книге; папа; современнои</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id    category                           keywords\n",
              "0    0       спорт                  у; хоккею; сеичас\n",
              "1    1    животные              собак; коробки; корма\n",
              "2    2       спорт      выбора; учащимся; навравления\n",
              "3    3  литература            вопросы; вопрос; задачи\n",
              "4    4  литература     тетради; множество; изобразите\n",
              "5    5       спорт                      при; он; дима\n",
              "6    6  литература          книг; сотыхвычисли; сотых\n",
              "7    7       спорт                 причем; гребца; но\n",
              "8    8       спорт               машина; наиди; ехала\n",
              "9    9       спорт     раздевалки; спортзала; гребцов\n",
              "10  10  литература     сочинения; сочинении; написать\n",
              "11  11       спорт         бассеина; раздевалки; пола\n",
              "12  12       спорт                   ловли; м; судака\n",
              "13  13       спорт              в; запиши; расстояние\n",
              "14  14       спорт                  он; турист; пошел\n",
              "15  15       спорт  велосипедиста; пешехода; определи\n",
              "16  16       спорт                   девушки; ведь; в\n",
              "17  17  литература                книге; о; кулинарии\n",
              "18  18       спорт                 было; где; беговая\n",
              "19  19  литература           книге; папа; современнои"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtMo9VG2EZzk"
      },
      "source": [
        "ans_df.to_csv(save_path + '/ans.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}