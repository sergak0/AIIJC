{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPD5xkHjefGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7878ddd1-961a-4383-a948-f1522f1357ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTfGP2b6Adn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b6a5f6-5f79-4f2a-e148-0dc7fd44cfe7"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.44-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
            "Collecting botocore<1.22.0,>=1.21.44\n",
            "  Downloading botocore-1.21.44-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 22.0 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.44->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.44->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.5.30)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.44 botocore-1.21.44 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRYkmf3b98vd"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjpegAf1_GJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57985535-ae85-4c33-867f-263477a2fba4"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        " \n",
        "if device == torch.device('cpu'):\n",
        "    print('Using cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Tesla K80 GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnXtMN6RE_i4"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNcjmF9KrOZB"
      },
      "source": [
        "save_path = '/content/drive/MyDrive'\n",
        "df_test = pd.read_csv(save_path + '/test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLsLFa0mr69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "5f65fc4b-f48e-405d-9827-799c86520e14"
      },
      "source": [
        "df_test.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>task</th>\n",
              "      <th>ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Вопрос 1 Денис готовится провести соревнования...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Реши задачу.\\nСколько коробок корма для собак ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Если групп элементов несколько, то применяется...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Вопрос1                                       ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Для наглядной геометрической иллюстрации объём...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Реши задачу в тетради.\\nДима осваивал новый ме...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Вопрос1\\nВыполни следующие задания.\\nВычисли с...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Перед тобой лежит карта возможных маршрутов дв...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>На первом участке дороги машина ехала 2 ч со с...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Скорость гребцов по течению реки составляет 23...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               task  ans\n",
              "0   0  Вопрос 1 Денис готовится провести соревнования...    0\n",
              "1   1  Реши задачу.\\nСколько коробок корма для собак ...    3\n",
              "2   2  Если групп элементов несколько, то применяется...    0\n",
              "3   3  Вопрос1                                       ...    3\n",
              "4   4  Для наглядной геометрической иллюстрации объём...    0\n",
              "5   5  Реши задачу в тетради.\\nДима осваивал новый ме...    0\n",
              "6   6  Вопрос1\\nВыполни следующие задания.\\nВычисли с...    2\n",
              "7   7  Перед тобой лежит карта возможных маршрутов дв...    0\n",
              "8   8  На первом участке дороги машина ехала 2 ч со с...    0\n",
              "9   9  Скорость гребцов по течению реки составляет 23...    0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3w8TpncEzKI"
      },
      "source": [
        "# Wiki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AxsOMzoeVev",
        "cellView": "code"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open(save_path + '/aiijc_comand_data.json', 'r') as f :\n",
        "  data = json.load(f)\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dajSzVWsAwO1",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2e5a0dcb-3290-46ae-a08b-771712b7cc85"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>животные</th>\n",
              "      <td>[Живо́тные (лат. Animalia) — традиционно (со в...</td>\n",
              "      <td>[Волосатики, Национальная парламентская библио...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>музыка</th>\n",
              "      <td>[Му́зыка (греч. μουσική, субстантивированное п...</td>\n",
              "      <td>[Мини-альбом, Волчья квинта, Ре (нота), Музыка...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>спорт</th>\n",
              "      <td>[Спорт (англ. sport, сокращение от первоначаль...</td>\n",
              "      <td>[Олимпийская хартия, Болельщик, Ольмеки, Шаоли...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>литература</th>\n",
              "      <td>[Литерату́ра (лат. lit(t)eratura, — написанное...</td>\n",
              "      <td>[Детская литература, Эфиопская литература, Сов...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        texts                                              links\n",
              "животные    [Живо́тные (лат. Animalia) — традиционно (со в...  [Волосатики, Национальная парламентская библио...\n",
              "музыка      [Му́зыка (греч. μουσική, субстантивированное п...  [Мини-альбом, Волчья квинта, Ре (нота), Музыка...\n",
              "спорт       [Спорт (англ. sport, сокращение от первоначаль...  [Олимпийская хартия, Болельщик, Ольмеки, Шаоли...\n",
              "литература  [Литерату́ра (лат. lit(t)eratura, — написанное...  [Детская литература, Эфиопская литература, Сов..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIuHgDn2luV6"
      },
      "source": [
        "# Facts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E0IX9PFlseJ"
      },
      "source": [
        "df = pd.read_csv(save_path + '/facts.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0CPn7oHqKJAR",
        "outputId": "aabf6bb1-3261-402c-ffef-6071beb6649e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1 Хамелеоны могут двигать глазами в разных нап...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 Белка – лучший садовник. Миллионы деревьев в...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 Зуб слона  может весить до девяти килограмм!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 У млекопитающих кровь красная, у насекомых ж...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5 В среднем коровы какают 16 раз в день.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  labels\n",
              "0  1 Хамелеоны могут двигать глазами в разных нап...       0\n",
              "1  2 Белка – лучший садовник. Миллионы деревьев в...       0\n",
              "2     3 Зуб слона  может весить до девяти килограмм!       0\n",
              "3  4 У млекопитающих кровь красная, у насекомых ж...       0\n",
              "4           5 В среднем коровы какают 16 раз в день.       0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EsrPQdN-4IQ"
      },
      "source": [
        "df_new = df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH98Wq2TziDX"
      },
      "source": [
        "# full_marked_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-hk8c4lzZs3"
      },
      "source": [
        "df = pd.read_csv(save_path + '/full_marked_dataset.csv')\n",
        "df = df.drop('Unnamed: 0', 1)\n",
        "df = df.rename(columns={'text': 'texts', 'ans': 'labels'})\n",
        "df.labels = df.labels.replace('животные', 0).replace('музыка', 1).replace('спорт', 2).replace('литература', 3).replace('неизвестно', 4)\n",
        "df = df.drop([i for i in range(len(df.labels)) if df.labels[i] == 4], 0)\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "hFFZqCxNzgDW",
        "outputId": "1728d4fa-efac-4d23-f721-6b1e2549ca0d"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\t1.1. Летом в спортивный лагерь ходили 50 дет...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\t1.2. На концерте в летнем лагере ребята игра...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\t1.4. Во время летних соревнований по плавани...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\t1.5. В спортивную школу во время летних кани...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\t1.7. Самые крупные животные на нашей планете...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\\t1.9. В летнем лагере ребята проходили медосм...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\\t1.11. Три кошки купили сапожки по паре на ка...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\\t1.17. Винтик и Шпунтик бежали наперегонки. К...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\\t1.18. Когда ребята для соревнований взяли 19...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\\t1.29. Вороны высиживают яйца три недели. Ско...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\\t1.30. В киоске 10 журналов, 14 брошюр1, а га...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\\t1.31. Грач приносил своим птенцам по 2 червя...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\\t1.41. В летние каникулы за день Наташа прочи...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\\t1.43. Две серые цапли съели на завтрак по 8 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\\t1.52. На уроке физкультуры Петя подтянулся 9...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\\t1.56. Во дворе гуляли 17 кур, 2 курицы убежа...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>\\t1.65. Утка может прожить 15 лет, а гусь – 18...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>\\t1.73. На полке 20 художественных книг. В пер...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>\\t1.78. В аквариуме было сначала несколько рыб...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>\\t2.1. Муравей нашёл соломинку возле дома и по...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                texts  labels\n",
              "0   \\t1.1. Летом в спортивный лагерь ходили 50 дет...       2\n",
              "1   \\t1.2. На концерте в летнем лагере ребята игра...       1\n",
              "2   \\t1.4. Во время летних соревнований по плавани...       2\n",
              "3   \\t1.5. В спортивную школу во время летних кани...       2\n",
              "4   \\t1.7. Самые крупные животные на нашей планете...       0\n",
              "5   \\t1.9. В летнем лагере ребята проходили медосм...       2\n",
              "6   \\t1.11. Три кошки купили сапожки по паре на ка...       0\n",
              "7   \\t1.17. Винтик и Шпунтик бежали наперегонки. К...       2\n",
              "8   \\t1.18. Когда ребята для соревнований взяли 19...       2\n",
              "9   \\t1.29. Вороны высиживают яйца три недели. Ско...       0\n",
              "10  \\t1.30. В киоске 10 журналов, 14 брошюр1, а га...       3\n",
              "11  \\t1.31. Грач приносил своим птенцам по 2 червя...       0\n",
              "12  \\t1.41. В летние каникулы за день Наташа прочи...       3\n",
              "13  \\t1.43. Две серые цапли съели на завтрак по 8 ...       0\n",
              "14  \\t1.52. На уроке физкультуры Петя подтянулся 9...       2\n",
              "15  \\t1.56. Во дворе гуляли 17 кур, 2 курицы убежа...       0\n",
              "16  \\t1.65. Утка может прожить 15 лет, а гусь – 18...       0\n",
              "17  \\t1.73. На полке 20 художественных книг. В пер...       3\n",
              "18  \\t1.78. В аквариуме было сначала несколько рыб...       0\n",
              "19  \\t2.1. Муравей нашёл соломинку возле дома и по...       0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovazZVao-7eP"
      },
      "source": [
        "# Facts & full_marked_dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbCDrYnZ-6gl"
      },
      "source": [
        "for i in range(len(df_new)):\n",
        "  df.loc[-i-1] = df_new.loc[i]\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X-y_j7IE5Pg"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "883a2936"
      },
      "source": [
        "categories = (\"животные\", \"музыка\", \"спорт\", \"литература\")\n",
        "categoriesTest = (\"спорт\", \"музыка\", \"литература\", \"животные\")\n",
        "catToCatTest = [3, 1, 0, 2]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86KGIlRwwCd"
      },
      "source": [
        "#sentMaxLen = 50\n",
        "sentMaxLen = 200\n",
        "max_len_tokenized = 200"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxbmPOVmmeVq"
      },
      "source": [
        "import string\n",
        " \n",
        "alphabet = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя ')\n",
        " \n",
        "max_texts = 1000\n",
        " \n",
        "def generateTexts(texts, windowLen, only_long=True):\n",
        "  out = []\n",
        "  # Wiki\n",
        "  \"\"\"\n",
        "  for text in tqdm(texts):\n",
        "  \"\"\"\n",
        "  # Facts\n",
        "  for text in texts:\n",
        "    text = text.lower().replace('\\n', ' ')\n",
        "    text = ''.join(c for c in text if c in alphabet)\n",
        "    text = text.split()\n",
        "    if only_long:\n",
        "      out.extend([' '.join(text[x:x+windowLen]) for x in range(0, len(text)-windowLen, windowLen)])\n",
        "    else:\n",
        "      out.extend([' '.join(text[x:x+windowLen]) for x in range(0, len(text), windowLen)])\n",
        "    if len(out) > max_texts:\n",
        "      break\n",
        "  return out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuc_PL2_oPYT"
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        " \n",
        "# Wiki\n",
        "\"\"\"\n",
        "for i, cat in enumerate(categories):\n",
        "  cat_texts = generateTexts(df.texts[cat], sentMaxLen)\n",
        "  label = i\n",
        "  for j in cat_texts:\n",
        "    sentences.append(j)\n",
        "    labels.append(label)\n",
        "\"\"\"\n",
        " \n",
        "# Facts\n",
        "for i in range(len(df.texts)):\n",
        "  cat_texts = generateTexts([df.texts[i]], sentMaxLen, only_long=False)\n",
        "  label = df.labels[i]\n",
        "  for j in cat_texts:\n",
        "    sentences.append(j)\n",
        "    labels.append(label)\n",
        " \n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "sentences = np.array(sentences)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpToKgtrS1A2",
        "outputId": "cd37e0f7-2cff-47b1-bc5d-464654474681"
      },
      "source": [
        "sentences.shape, sentences[5], labels[5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1421,),\n",
              " '[CLS] в летнем лагере ребята проходили медосмотр медсестра измеряла их рост оказалось что настя выше кати на см а маша ниже кати на см на сколько сантиметров самая высокая девочка выше самой низкой [SEP]',\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z9PspheJafk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "X_train = sentences\n",
        "Y_train = labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6C6raB6KhYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5affab4c-f641-431b-ea69-9ce3f8e25b3e"
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        " \n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\", do_lower_case=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 871891/871891 [00:01<00:00, 772490.44B/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veRZY_NyZ92O"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in X_train]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfBAJSnaT7SI",
        "outputId": "58d0a553-2898-43b4-ee83-bc16f79fc763"
      },
      "source": [
        "len(tokenized_texts[0]), tokenized_texts[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30,\n",
              " ['[CLS]',\n",
              "  'летом',\n",
              "  'в',\n",
              "  'спорт',\n",
              "  '##ивныи',\n",
              "  'ла',\n",
              "  '##гер',\n",
              "  '##ь',\n",
              "  'ход',\n",
              "  '##или',\n",
              "  'детеи',\n",
              "  'из',\n",
              "  'них',\n",
              "  'дев',\n",
              "  '##о',\n",
              "  '##чек',\n",
              "  'с',\n",
              "  '##колько',\n",
              "  'мал',\n",
              "  '##ь',\n",
              "  '##чиков',\n",
              "  'ход',\n",
              "  '##или',\n",
              "  'в',\n",
              "  'спорт',\n",
              "  '##ивныи',\n",
              "  'ла',\n",
              "  '##гер',\n",
              "  '##ь',\n",
              "  '[SEP]'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owLBLIY1Lj9U"
      },
      "source": [
        "tokenized_texts = pad_sequences(\n",
        "  tokenized_texts,\n",
        "  maxlen=max_len_tokenized,\n",
        "  dtype=object,\n",
        "  truncating=\"post\",\n",
        "  padding=\"post\",\n",
        "  value='[PAD]'\n",
        ")\n",
        " \n",
        "attention_masks = [[1 if i != '[PAD]' else 0 for i in seq] for seq in tokenized_texts]\n",
        " \n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UPjvURwLuk6"
      },
      "source": [
        "#train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, Y_train, random_state=42, test_size=0.1)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, Y_train, random_state=42, test_size=0.01)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.01)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO4N-7wzNLQB"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIg8YRFeNO4S",
        "outputId": "8682c056-ed34-465c-9b19-41acbab878fe"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 0,  ..., 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQlkgEm2NSra"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "  train_data,\n",
        "  sampler=RandomSampler(train_data),\n",
        "  batch_size=20\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DauzvK1UNdi6"
      },
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZdB2Hw0NpUJ",
        "outputId": "3a881a53-ede7-4e69-dfe0-cace32fc67c4"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=4, output_hidden_states=True, output_attentions=True)\n",
        "#model.load_state_dict(torch.load(save_path + '/model_facts.pth'))\n",
        "model.to(device)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:00<00:00, 384883.28B/s]\n",
            "100%|██████████| 672271273/672271273 [00:45<00:00, 14887322.32B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d63qzJeuNzfY"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "  {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.01},\n",
        "  {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "#optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTfNZ44FN3tY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3be82c78-8d0c-4551-dcc8-1065df47bd57"
      },
      "source": [
        "from IPython.display import clear_output\n",
        " \n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        " \n",
        "model.train()\n",
        " \n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "  \n",
        "  train_loss_set.append(loss[0].item())  \n",
        "  \n",
        "  loss[0].backward()\n",
        "  \n",
        "  \n",
        "  optimizer.step()\n",
        " \n",
        "  train_loss += loss[0].item()\n",
        "  \n",
        "  clear_output(True)\n",
        "  plt.plot(train_loss_set)\n",
        "  plt.title(\"Training loss\")\n",
        "  plt.xlabel(\"Batch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a48zM7vaQ4I"
      },
      "source": [
        "torch.save(model.state_dict(), save_path + '/model_full_marked_dataset_plus_facts_2.pth')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO-D7e2oNkjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6bbcf5b-5b08-4930-a426-725f1c735f74"
      },
      "source": [
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        " \n",
        "model.eval()\n",
        " \n",
        "valid_preds, valid_labels = [], []\n",
        " \n",
        "for i in range(len(validation_inputs)):\n",
        "  b_input_ids = torch.tensor(np.array([validation_inputs[i]])).to(device)\n",
        "  b_labels = torch.tensor(validation_labels[i]).to(device)\n",
        "  b_input_mask = torch.tensor(np.array([validation_masks[i]])).to(device)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " \n",
        "  logits = logits[0].detach().to('cpu').numpy()  \n",
        "  preds = np.argmax(logits, axis=1).item()\n",
        "  valid_preds.append(preds)\n",
        "  valid_labels.append(b_labels.to('cpu').numpy().item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss на обучающей выборке: 0.49855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecX8LZN8fkPw",
        "outputId": "04b76e00-9186-4eca-8b2d-e48fd53c007e"
      },
      "source": [
        "print(\"Accuracy на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))\n",
        "print(\"f1: {0:.2f}%\".format(\n",
        "    f1_score(valid_labels, valid_preds, average='macro') * 100\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на валидационной выборке: 81.08%\n",
            "f1: 83.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynyn_t93ECwu"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na9t7owFB4rL"
      },
      "source": [
        "sentencesTest = []\n",
        "labelsTest = df_test.ans\n",
        " \n",
        "for text in df_test.task:\n",
        "  text = text.lower().replace('\\n', ' ')\n",
        "  text = ''.join(c for c in text if c in alphabet)\n",
        "  text = ' '.join(text.split())\n",
        "  sentencesTest.append(text)\n",
        " \n",
        "sentencesTest = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentencesTest]\n",
        "sentencesTest = np.array(sentencesTest)\n",
        "labelsTest = np.array(labelsTest)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_2ydIDPjD0O",
        "outputId": "256ab474-c4b1-4e72-d5fa-bb400e431d4c"
      },
      "source": [
        "sentencesTest.shape, sentencesTest[0]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((514,),\n",
              " '[CLS] вопрос денис готовится провести соревнования по настольному хоккею и решил распечатать недостающие фигурки на принторе для изготовления одной модели у дениса слишком мало времени поэтому он решает использовать принтера сразу а потом склеить полученные детали у специалиста сейчас в наличии принтеров сколько у него есть вариантов выбора если сначала он настраивает один из принтеров а за ним второй [SEP]')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FksbomRADmPs"
      },
      "source": [
        "tokenized_textsTest = [tokenizer.tokenize(sent) for sent in sentencesTest]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGP_VZ-5j6Ie",
        "outputId": "5ea470ee-1ef6-465b-d0dc-b551f7e933db"
      },
      "source": [
        "len(tokenized_textsTest[0]), tokenized_textsTest[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103,\n",
              " ['[CLS]',\n",
              "  'вопрос',\n",
              "  'денис',\n",
              "  'го',\n",
              "  '##тов',\n",
              "  '##ится',\n",
              "  'провести',\n",
              "  'соревнования',\n",
              "  'по',\n",
              "  'нас',\n",
              "  '##то',\n",
              "  '##льному',\n",
              "  'х',\n",
              "  '##ок',\n",
              "  '##ке',\n",
              "  '##ю',\n",
              "  'и',\n",
              "  'решил',\n",
              "  'ра',\n",
              "  '##сп',\n",
              "  '##еч',\n",
              "  '##ата',\n",
              "  '##ть',\n",
              "  'не',\n",
              "  '##до',\n",
              "  '##ста',\n",
              "  '##ющие',\n",
              "  'ф',\n",
              "  '##и',\n",
              "  '##гу',\n",
              "  '##рки',\n",
              "  'на',\n",
              "  'при',\n",
              "  '##нт',\n",
              "  '##оре',\n",
              "  'для',\n",
              "  'из',\n",
              "  '##го',\n",
              "  '##тов',\n",
              "  '##ления',\n",
              "  'однои',\n",
              "  'модели',\n",
              "  'у',\n",
              "  'денис',\n",
              "  '##а',\n",
              "  'слишком',\n",
              "  'мало',\n",
              "  'времени',\n",
              "  'поэтому',\n",
              "  'он',\n",
              "  'р',\n",
              "  '##еш',\n",
              "  '##ает',\n",
              "  'использовать',\n",
              "  'при',\n",
              "  '##нте',\n",
              "  '##ра',\n",
              "  'сразу',\n",
              "  'а',\n",
              "  'потом',\n",
              "  'с',\n",
              "  '##кле',\n",
              "  '##ить',\n",
              "  'полу',\n",
              "  '##ченные',\n",
              "  'де',\n",
              "  '##тали',\n",
              "  'у',\n",
              "  'специалист',\n",
              "  '##а',\n",
              "  'сеичас',\n",
              "  'в',\n",
              "  'на',\n",
              "  '##ли',\n",
              "  '##чии',\n",
              "  'при',\n",
              "  '##нте',\n",
              "  '##ров',\n",
              "  'с',\n",
              "  '##колько',\n",
              "  'у',\n",
              "  'него',\n",
              "  'есть',\n",
              "  'вариант',\n",
              "  '##ов',\n",
              "  'выбор',\n",
              "  '##а',\n",
              "  'если',\n",
              "  'сначала',\n",
              "  'он',\n",
              "  'нас',\n",
              "  '##тра',\n",
              "  '##ивает',\n",
              "  'один',\n",
              "  'из',\n",
              "  'при',\n",
              "  '##нте',\n",
              "  '##ров',\n",
              "  'а',\n",
              "  'за',\n",
              "  'ним',\n",
              "  'второи',\n",
              "  '[SEP]'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZQYQ3z0EHDN"
      },
      "source": [
        "tokenized_textsTest = pad_sequences(\n",
        "  tokenized_textsTest,\n",
        "  maxlen=max_len_tokenized,\n",
        "  dtype=object,\n",
        "  truncating=\"post\",\n",
        "  padding=\"post\",\n",
        "  value='[PAD]'\n",
        ")\n",
        " \n",
        "attention_masksTest = [[1 if i != '[PAD]' else 0 for i in seq] for seq in tokenized_textsTest]\n",
        " \n",
        "input_idsTest = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_textsTest]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7ntEiHJEZ19"
      },
      "source": [
        "test_preds, test_labels = [], []\n",
        " \n",
        "for i in range(len(input_idsTest)):\n",
        "  b_input_ids = torch.tensor(np.array([input_idsTest[i]])).to(device)\n",
        "  b_labels = torch.tensor(labelsTest[i]).to(device)\n",
        "  b_input_mask = torch.tensor(np.array([attention_masksTest[i]])).to(device)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " \n",
        "  logits = logits[0].detach().to('cpu').numpy()\n",
        "  preds = np.argmax(logits, axis=1).item()\n",
        "  test_preds.append(preds)\n",
        "  test_labels.append(b_labels.to('cpu').numpy().item())"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7AKDdclktHs"
      },
      "source": [
        "for i in range(len(test_preds)):\n",
        "  test_preds[i] = catToCatTest[test_preds[i]]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS1HE5zPib7o",
        "outputId": "3bef51be-44b8-4aba-e9ff-9faf7f8e5792"
      },
      "source": [
        "print(\"Accuracy на тестовой выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(test_labels, test_preds) * 100\n",
        "))\n",
        "print(\"f1: {0:.2f}%\".format(\n",
        "    f1_score(test_labels, test_preds, average='macro') * 100\n",
        "))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy на тестовой выборке: 78.99%\n",
            "f1: 76.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-KlrOfbbnCY"
      },
      "source": [
        "# Any test & make csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbi9MLv4fvwU"
      },
      "source": [
        "def prediction(sentence, max_key_words=1):\n",
        "  sentence = sentence.lower().replace('\\n', ' ').replace('ё', 'е').replace('й', 'и')\n",
        "  sentence = ''.join(c for c in sentence if c in alphabet)\n",
        "  sentence = ' '.join(sentence.split()[:max_len_tokenized])\n",
        "  sentence = '[CLS] ' + sentence + ' [SEP]'\n",
        "  words = sentence.split()\n",
        "  tokenized = tokenizer.tokenize(sentence)\n",
        "\n",
        "  now_word = 0\n",
        "  now_ind = 0\n",
        "  token_to_word = []\n",
        "  for i in tokenized:\n",
        "    token_to_word.append(now_word)\n",
        "    for j in range(len(i)):\n",
        "      if i[j] != words[now_word][now_ind]:\n",
        "        continue\n",
        "      now_ind += 1\n",
        "      if now_ind == len(words[now_word]):\n",
        "        now_ind = 0\n",
        "        now_word += 1\n",
        "  \n",
        "  ids = [tokenizer.convert_tokens_to_ids(tokenized)]\n",
        "  ids = torch.tensor(ids)\n",
        "  ids = ids.to(device)\n",
        "  label = torch.tensor([0]).to(device)\n",
        "  with torch.no_grad():\n",
        "    logits = model(ids, token_type_ids=None, attention_mask=None, labels=label)\n",
        "  \n",
        "  ans = logits[1].detach().to('cpu').numpy()\n",
        "  ans_ind = np.argmax(ans, axis=1).item()\n",
        "  ans_cat = categories[ans_ind]\n",
        "\n",
        "  attention = logits[3][11][0][11][0].detach().to('cpu').numpy()\n",
        "  max_inds = np.flip(np.argsort(attention))\n",
        "  all_key_words = ['[SEP]', '[CLS]']\n",
        "  for i in max_inds:\n",
        "    if words[token_to_word[i]] in all_key_words:\n",
        "      continue\n",
        "    all_key_words.append(words[token_to_word[i]])\n",
        "    if len(all_key_words)-2 == max_key_words:\n",
        "      break\n",
        "  return ans_cat, all_key_words[2:]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSKfnzp5X4on",
        "outputId": "3cee3871-3a65-44db-ca15-f3baba445372"
      },
      "source": [
        "ans_cat, all_key_words = prediction('1.29. Вороны высиживают яйца три недели. Сколько дней высиживают яйца вороны?', 3)\n",
        "print(ans_cat)\n",
        "print(all_key_words)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "животные\n",
            "['вороны', 'высиживают', 'сколько']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74hVZYzaCz-Z"
      },
      "source": [
        "ans_csv = []\n",
        "for i, text in enumerate(df_test.task):\n",
        "  ans_cat, all_key_words = prediction(text, 3)\n",
        "  ans_csv.append([i, ans_cat, '; '.join(all_key_words)])\n",
        "\n",
        "ans_df = pd.DataFrame(ans_csv, columns=['id', 'category', 'keywords'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "MBS4MWIeEZjR",
        "outputId": "2977a67b-7e2f-43a8-d969-c6a2b1219d6e"
      },
      "source": [
        "ans_df.head(20)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>спорт</td>\n",
              "      <td>настольному; фигурки; хоккею</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>животные</td>\n",
              "      <td>собак; сколько; коробок</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>спорт</td>\n",
              "      <td>волеиболу; легкои; группы</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>животные</td>\n",
              "      <td>описанная; оформил; потратил</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>спорт</td>\n",
              "      <td>шестиклассников; самостоятельно; проверьте</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>спорт</td>\n",
              "      <td>тетради; отжимании; в</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>литература</td>\n",
              "      <td>вычисли; следующие; задания</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>спорт</td>\n",
              "      <td>тина; каменистыи; водоросли</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>спорт</td>\n",
              "      <td>на; а; машина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>спорт</td>\n",
              "      <td>раздевалки; вычисли; гребцов</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>литература</td>\n",
              "      <td>написали; которое; сочинения</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>спорт</td>\n",
              "      <td>раздевалки; задачу; в</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>спорт</td>\n",
              "      <td>изготовил; купил; ловли</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>спорт</td>\n",
              "      <td>электросамокате; запиши; измерения</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>спорт</td>\n",
              "      <td>другои; москвои; вологде</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>спорт</td>\n",
              "      <td>определи; пешеход; пешехода</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>спорт</td>\n",
              "      <td>спортивную; даша; ангелина</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>животные</td>\n",
              "      <td>груши; кулинарии; говорится</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>спорт</td>\n",
              "      <td>расстановку; габариты; дорожка</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>литература</td>\n",
              "      <td>покупки; планирования; выполнить</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id    category                                    keywords\n",
              "0    0       спорт                настольному; фигурки; хоккею\n",
              "1    1    животные                     собак; сколько; коробок\n",
              "2    2       спорт                   волеиболу; легкои; группы\n",
              "3    3    животные                описанная; оформил; потратил\n",
              "4    4       спорт  шестиклассников; самостоятельно; проверьте\n",
              "5    5       спорт                       тетради; отжимании; в\n",
              "6    6  литература                 вычисли; следующие; задания\n",
              "7    7       спорт                 тина; каменистыи; водоросли\n",
              "8    8       спорт                               на; а; машина\n",
              "9    9       спорт                раздевалки; вычисли; гребцов\n",
              "10  10  литература                написали; которое; сочинения\n",
              "11  11       спорт                       раздевалки; задачу; в\n",
              "12  12       спорт                     изготовил; купил; ловли\n",
              "13  13       спорт          электросамокате; запиши; измерения\n",
              "14  14       спорт                    другои; москвои; вологде\n",
              "15  15       спорт                 определи; пешеход; пешехода\n",
              "16  16       спорт                  спортивную; даша; ангелина\n",
              "17  17    животные                 груши; кулинарии; говорится\n",
              "18  18       спорт              расстановку; габариты; дорожка\n",
              "19  19  литература            покупки; планирования; выполнить"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtMo9VG2EZzk"
      },
      "source": [
        "ans_df.to_csv(save_path + '/ans.csv', index=False)"
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}