{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPD5xkHjefGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6f51c1-f77f-4eda-bfdb-539ad3520452"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTfGP2b6Adn3"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRYkmf3b98vd"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjpegAf1_GJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abf834f-6997-4ffb-cb32-0604e4df04be"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device == torch.device('cpu'):\n",
        "    print('Using cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tesla K80 GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnXtMN6RE_i4"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNcjmF9KrOZB"
      },
      "source": [
        "save_path = '/content/drive/MyDrive'\n",
        "df_test = pd.read_csv(save_path + '/test.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLsLFa0mr69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "3529c615-f17b-4238-ed3d-0f2483f3dbdf"
      },
      "source": [
        "df_test.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>task</th>\n",
              "      <th>ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Вопрос 1 Денис готовится провести соревнования...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Реши задачу.\\nСколько коробок корма для собак ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Если групп элементов несколько, то применяется...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Вопрос1                                       ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Для наглядной геометрической иллюстрации объём...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Реши задачу в тетради.\\nДима осваивал новый ме...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Вопрос1\\nВыполни следующие задания.\\nВычисли с...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Перед тобой лежит карта возможных маршрутов дв...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>На первом участке дороги машина ехала 2 ч со с...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Скорость гребцов по течению реки составляет 23...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               task  ans\n",
              "0   0  Вопрос 1 Денис готовится провести соревнования...    0\n",
              "1   1  Реши задачу.\\nСколько коробок корма для собак ...    3\n",
              "2   2  Если групп элементов несколько, то применяется...    0\n",
              "3   3  Вопрос1                                       ...    3\n",
              "4   4  Для наглядной геометрической иллюстрации объём...    0\n",
              "5   5  Реши задачу в тетради.\\nДима осваивал новый ме...    0\n",
              "6   6  Вопрос1\\nВыполни следующие задания.\\nВычисли с...    2\n",
              "7   7  Перед тобой лежит карта возможных маршрутов дв...    0\n",
              "8   8  На первом участке дороги машина ехала 2 ч со с...    0\n",
              "9   9  Скорость гребцов по течению реки составляет 23...    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjj4ec5lrlwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e4e895-7f71-4c60-ecd6-f3fc1958f581"
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(514, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3w8TpncEzKI"
      },
      "source": [
        "# Wiki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AxsOMzoeVev",
        "cellView": "code"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "save_path = '/content/drive/MyDrive/'\n",
        "with open(save_path + 'aiijc_comand_data.json', 'r') as f :\n",
        "  data = json.load(f)\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dajSzVWsAwO1",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2d9d2847-7b40-4f0f-ae50-4b0d2ecb5fac"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>животные</th>\n",
              "      <td>[Живо́тные (лат. Animalia) — традиционно (со в...</td>\n",
              "      <td>[Волосатики, Национальная парламентская библио...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>музыка</th>\n",
              "      <td>[Му́зыка (греч. μουσική, субстантивированное п...</td>\n",
              "      <td>[Мини-альбом, Волчья квинта, Ре (нота), Музыка...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>спорт</th>\n",
              "      <td>[Спорт (англ. sport, сокращение от первоначаль...</td>\n",
              "      <td>[Олимпийская хартия, Болельщик, Ольмеки, Шаоли...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>литература</th>\n",
              "      <td>[Литерату́ра (лат. lit(t)eratura, — написанное...</td>\n",
              "      <td>[Детская литература, Эфиопская литература, Сов...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        texts                                              links\n",
              "животные    [Живо́тные (лат. Animalia) — традиционно (со в...  [Волосатики, Национальная парламентская библио...\n",
              "музыка      [Му́зыка (греч. μουσική, субстантивированное п...  [Мини-альбом, Волчья квинта, Ре (нота), Музыка...\n",
              "спорт       [Спорт (англ. sport, сокращение от первоначаль...  [Олимпийская хартия, Болельщик, Ольмеки, Шаоли...\n",
              "литература  [Литерату́ра (лат. lit(t)eratura, — написанное...  [Детская литература, Эфиопская литература, Сов..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYRVCLo1CBs1",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0ff15b-eebf-482a-aa7c-e683bae16886"
      },
      "source": [
        "len(np.array(df.texts[0])[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X-y_j7IE5Pg"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "883a2936"
      },
      "source": [
        "categories = (\"животные\", \"музыка\", \"спорт\", \"литература\")\n",
        "categoriesTest = (\"спорт\", \"музыка\", \"литература\", \"животные\")\n",
        "catToCatTest = [3, 1, 0, 2]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFvUOktsHXC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8669b0c6-73e3-4f19-af71-ec3d215e1d5f"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxbmPOVmmeVq"
      },
      "source": [
        "stopWordsRu = set(stopwords.words(\"russian\"))\n",
        "punctuation = set(string.punctuation + \"—\")\n",
        " \n",
        "alphabet = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя1234567890')\n",
        " \n",
        "def validateWord(word):\n",
        "  if word in stopWordsRu or word in punctuation:\n",
        "    return False\n",
        "  allSymValid = True\n",
        " \n",
        "  for sym in word:\n",
        "    if sym not in alphabet and sym not in punctuation:\n",
        "      allSymValid = False\n",
        "      break\n",
        " \n",
        "  return allSymValid\n",
        " \n",
        "def prepareText(text:str) -> list:\n",
        "  out = ''\n",
        "  for word in nltk.word_tokenize(text):\n",
        "    word = word.strip()\n",
        "    word = word.lower()\n",
        "    if not validateWord(word):\n",
        "      continue\n",
        "    out += word + ' '\n",
        "  return out\n",
        " \n",
        " \n",
        "def generateTexts(texts, windowLen, need_prepare = True) -> list:\n",
        "  out = []\n",
        "  for text in tqdm(texts):\n",
        "    byWords = text.split(' ')\n",
        "    for window in range(len(byWords) // windowLen + 1):\n",
        "      textPrepare = \" \".join(byWords[window * windowLen: (window + 1) * windowLen])\n",
        "      if need_prepare:\n",
        "        prepared = prepareText(textPrepare)\n",
        "      else:\n",
        "        prepared = textPrepare\n",
        "        \n",
        "      if windowLen - len(prepared) > 0:\n",
        "        prepared += \" \" * ( windowLen - len(prepared))\n",
        "      out.append(prepared)\n",
        "  return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86KGIlRwwCd"
      },
      "source": [
        "sentMaxLen = 50\n",
        "MaxSymb = 200"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuc_PL2_oPYT",
        "outputId": "c83541aa-fe4d-41cf-eb62-04e4f375afe0"
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for i, cat in enumerate(categories):\n",
        "  print(i)\n",
        "  cat_texts = generateTexts(df.texts[cat], sentMaxLen)\n",
        "  label = i\n",
        "  for j in cat_texts:\n",
        "    sentences.append(j[:MaxSymb])\n",
        "    labels.append(label)\n",
        "\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "sentences = np.array(sentences)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 444/444 [00:13<00:00, 33.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 431/431 [00:13<00:00, 31.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 424/424 [00:15<00:00, 27.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 433/433 [00:17<00:00, 24.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYa4y4-xCOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df270c4c-3b17-41d1-d221-43d7807495f0"
      },
      "source": [
        "sentences.shape, labels.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((74687,), (74687,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z9PspheJafk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = sentences\n",
        "Y_train = labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6C6raB6KhYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d813e1e8-8fa6-409b-d36f-9846b217a315"
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in X_train]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 995526/995526 [00:01<00:00, 886548.66B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYLw6FWTKsAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f061fb-da99-48ea-ac6c-5cd8691867b5"
      },
      "source": [
        "len(tokenized_texts[0]), tokenized_texts[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49,\n",
              " ['[CLS]',\n",
              "  'лат',\n",
              "  'т',\n",
              "  '##радиционно',\n",
              "  'време',\n",
              "  '##н',\n",
              "  'ар',\n",
              "  '##ист',\n",
              "  '##от',\n",
              "  '##еля',\n",
              "  'вы',\n",
              "  '##деля',\n",
              "  '##ема',\n",
              "  '##я',\n",
              "  'ка',\n",
              "  '##те',\n",
              "  '##гория',\n",
              "  'органи',\n",
              "  '##зм',\n",
              "  '##ов',\n",
              "  'настоящее',\n",
              "  'время',\n",
              "  'р',\n",
              "  '##ас',\n",
              "  '##с',\n",
              "  '##мат',\n",
              "  '##рива',\n",
              "  '##ема',\n",
              "  '##я',\n",
              "  'качестве',\n",
              "  'био',\n",
              "  '##логического',\n",
              "  'царства',\n",
              "  'живот',\n",
              "  '##ные',\n",
              "  'являются',\n",
              "  'основным',\n",
              "  'объект',\n",
              "  '##ом',\n",
              "  'изучения',\n",
              "  'з',\n",
              "  '##оо',\n",
              "  '##логии',\n",
              "  'живот',\n",
              "  '##ные',\n",
              "  'от',\n",
              "  '##нос',\n",
              "  '##ят',\n",
              "  '[SEP]'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owLBLIY1Lj9U"
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(\n",
        "  input_ids,\n",
        "  maxlen=200,\n",
        "  dtype=\"long\",\n",
        "  truncating=\"post\",\n",
        "  padding=\"post\"\n",
        ")\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_vMbpiF9Fif",
        "outputId": "d2f1ea59-c0c5-4c9f-da86-1a30491a361f"
      },
      "source": [
        "len(attention_masks)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UPjvURwLuk6"
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, Y_train, random_state=42, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO4N-7wzNLQB"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0oO8sY3NNIZ"
      },
      "source": [
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIg8YRFeNO4S",
        "outputId": "f012e0c9-a9c7-4e7c-9321-114040af4147"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 2,  ..., 3, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQlkgEm2NSra"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "  train_data,\n",
        "  sampler=RandomSampler(train_data),\n",
        "  batch_size=16\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgolTh1nNa0J"
      },
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "  validation_data,\n",
        "  sampler=SequentialSampler(validation_data),\n",
        "  batch_size=16\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DauzvK1UNdi6"
      },
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZdB2Hw0NpUJ",
        "outputId": "7e3d98ef-c5af-429c-d30e-34bf43978fb3"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=4)\n",
        "model.to(device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [00:00<00:00, 132966.78B/s]\n",
            "100%|██████████| 714314041/714314041 [01:04<00:00, 11000379.91B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d63qzJeuNzfY"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "  {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.01},\n",
        "  {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "PTfNZ44FN3tY",
        "outputId": "c621c9f7-f716-4c06-bbaa-7333e6bf4116"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "model.train()\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "  train_loss_set.append(loss[0].item())  \n",
        "  \n",
        "  loss[0].backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "\n",
        "  train_loss += loss[0].item()\n",
        "  \n",
        "  clear_output(True)\n",
        "  plt.plot(train_loss_set)\n",
        "  plt.title(\"Training loss\")\n",
        "  plt.xlabel(\"Batch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-37f2f1a089fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mtrain_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO-D7e2oNkjh",
        "outputId": "eaeda519-bfab-4250-abb5-72f6d223e155"
      },
      "source": [
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  logits = logits[0].detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  batch_preds = np.argmax(logits, axis=1)\n",
        "  batch_labels = label_ids\n",
        "  valid_preds.extend(batch_preds)\n",
        "  valid_labels.extend(batch_labels)\n",
        "\n",
        "print(\"Accuracy на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))\n",
        "print(\"f1: {0:.2f}%\".format(\n",
        "    f1_score(valid_labels, valid_preds, average='macro') * 100\n",
        "))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss на обучающей выборке: 0.63815\n",
            "Accuracy на валидационной выборке: 66.88%\n",
            "f1: 66.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hft1n_z1Y0y"
      },
      "source": [
        "valid_labels, valid_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynyn_t93ECwu"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5sanqcuC0XG"
      },
      "source": [
        "def generateTextsTest(texts, windowLen, need_prepare = True) -> list:\n",
        "  out = []\n",
        "  byWords = texts.split(' ')\n",
        "  for window in range(len(byWords) // windowLen + 1):\n",
        "    textPrepare = \" \".join(byWords[window * windowLen: (window + 1) * windowLen])\n",
        "    if need_prepare :\n",
        "      prepared = prepareText(textPrepare)\n",
        "    else :\n",
        "      prepared = textPrepare\n",
        "      \n",
        "    if windowLen - len(prepared) > 0:\n",
        "      prepared += ' ' * ( windowLen - len(prepared))\n",
        "    out.append(prepared)\n",
        "  return out"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na9t7owFB4rL"
      },
      "source": [
        "\"\"\"\n",
        "sentencesTest = []\n",
        "labelsTest = []\n",
        "\n",
        "for i in range(df_test.shape[0]):\n",
        "  print(i)\n",
        "  cat_texts = generateTextsTest(df_test.task[i], sentMaxLen)\n",
        "  label = df_test.ans[i]\n",
        "  for j in cat_texts:\n",
        "    sentencesTest.append(j)\n",
        "    labelsTest.append(label)\n",
        "\"\"\"\n",
        "\n",
        "sentencesTest = df_test.task\n",
        "labelsTest = df_test.ans\n",
        "\n",
        "sentencesTest = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentencesTest]\n",
        "sentencesTest = np.array(sentencesTest)\n",
        "labelsTest = np.array(labelsTest)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FksbomRADmPs"
      },
      "source": [
        "tokenized_textsTest = [tokenizer.tokenize(sent) for sent in sentencesTest]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZQYQ3z0EHDN",
        "outputId": "48c2f458-ed4d-43ef-cd6d-42525bbfafe6"
      },
      "source": [
        "input_idsTest = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_textsTest]\n",
        "input_idsTest = pad_sequences(\n",
        "  input_idsTest,\n",
        "  maxlen=200,\n",
        "  dtype=\"long\",\n",
        "  truncating=\"post\",\n",
        "  padding=\"post\"\n",
        ")\n",
        "attention_masksTest = [[float(i>0) for i in seq] for seq in input_idsTest]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1655 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9XiQKVXEQjl"
      },
      "source": [
        "test_inputs = torch.tensor(input_idsTest)\n",
        "test_labels = torch.tensor(labelsTest)\n",
        "test_masks = torch.tensor(attention_masksTest)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8KLxVUcEZYl"
      },
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_dataloader = DataLoader(\n",
        "  test_data,\n",
        "  sampler=SequentialSampler(test_data),\n",
        "  batch_size=16\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7ntEiHJEZ19",
        "outputId": "06afed10-db3c-4bc9-a64e-4dfe5ad52206"
      },
      "source": [
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  logits = logits[0].detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  batch_preds = np.argmax(logits, axis=1)\n",
        "  batch_labels = label_ids\n",
        "  test_preds.extend(batch_preds)\n",
        "  test_labels.extend(batch_labels)\n",
        "\n",
        "for i in range(len(test_preds)):\n",
        "  test_preds[i] = catToCatTest[test_preds[i]]\n",
        "\n",
        "print(\"Accuracy предсказаний на тестовой выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(test_labels, test_preds) * 100\n",
        "))\n",
        "print(\"f1: {0:.2f}%\".format(\n",
        "    f1_score(test_labels, test_preds, average='macro') * 100\n",
        "))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy предсказаний на тестовой выборке: 69.65%\n",
            "f1: 63.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4P3hzNhE7M1",
        "outputId": "186870ac-b700-4d94-8eef-9e7f37f44a61"
      },
      "source": [
        "test_labels, test_preds"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  2],\n",
              " [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Z_TALbEhtV",
        "outputId": "19c40815-ded0-4f6d-961e-61b20c048052"
      },
      "source": [
        "len(test_labels), len(test_preds)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(514, 514)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}